---
title: "Section 3 Random Variables"
author: "kevinoliva26"
date: "5/14/2021"
output: html_document
---

## Random Variables

```{r}
# define random variable x to be 1 if blue, 0 otherwise
beads <- rep(c("red", "blue"), times = c(2, 3))
x <- ifelse(sample(beads, 1) == "blue", 1, 0)
# demonstrate that the random variable is different every time
ifelse(sample(beads, 1) == "blue", 1, 0)
ifelse(sample(beads, 1) == "blue", 1, 0)
ifelse(sample(beads, 1) == "blue", 1, 0)
```

##Sampling Models

A sampling model models the random behavior of a process as the sampling of draws from an urn.
The probability distribution of a random variable is the probability of the observed value falling in any given interval.
We can define a CDF  *F(a)=Pr(S≤a)*  to answer questions related to the probability of S being in any interval.
The average of many draws of a random variable is called its *expected value*.
The standard deviation of many draws of a random variable is called its *standard error*.

Monte Carlo simulation: Chance of casino losing money on roulette
```{r}
# sampling model 1: define urn, then sample
color <- rep(c("Black", "Red", "Green"), c(18, 18, 2)) # define the urn for the sampling model
n <- 1000
X <- sample(ifelse(color == "Red", -1, 1), n, replace = TRUE)
X[1:10]
# sampling model 2: define urn inside sample function by noting probabilities
x <- sample(c(-1, 1), n, replace = TRUE, prob = c(9/19, 10/19))    # 1000 independent draws
S <- sum(x)    # total winnings = sum of draws
S
```

We use the sampling model to run a Monte Carlo simulation and use the results to estimate the probability of the casino losing money.
```{r}
n <- 1000    # number of roulette players
B <- 10000    # number of Monte Carlo experiments
S <- replicate(B, {
    X <- sample(c(-1,1), n, replace = TRUE, prob = c(9/19, 10/19))    # simulate 1000 spins
    sum(X)    # determine total profit
})
mean(S < 0)    # probability of the casino losing money
```

We can plot a histogram of the observed values of S as well as the normal density curve based on the mean and standard deviation of S.
```{r}
library(tidyverse)
s <- seq(min(S), max(S), length = 100)    # sequence of 100 values across range of S
normal_density <- data.frame(s = s, f = dnorm(s, mean(S), sd(S))) # generate normal density for S
data.frame (S = S) %>%    # make data frame of S for histogram
    ggplot(aes(S, ..density..)) +
    geom_histogram(color = "black", binwidth = 10) +
    ylab("Probability") +
    geom_line(data = normal_density, mapping = aes(s, f), color = "blue")
```

##Distributions versus Probability Distributions

A random variable X has a probability distribution function F(a) that defines Pr(X≤a) over all values of a.
Any list of numbers has a distribution. The probability distribution function of a random variable is defined mathematically and does not depend on a list of numbers.
The results of a Monte Carlo simulation with a large enough number of observations will approximate the probability distribution of X.
If a random variable is defined as draws from an urn:
The probability distribution function of the random variable is defined as the distribution of the list of values in the urn.
The expected value of the random variable is the average of values in the urn.
The standard error of one draw of the random variable is the standard deviation of the values of the urn.

##Notation for Random Variables

Capital letters denote random variables (X) and lowercase letters denote observed values (x).

##Central Limit Theorem

The Central Limit Theorem (CLT) says that the distribution of the sum of a random variable is approximated by a normal distribution.

The expected value of a random variable, E[X]=μ, is the average of the values in the urn. This represents the expectation of one draw. 

The standard error of one draw of a random variable is the standard deviation of the values in the urn.

The expected value of the sum of draws is the number of draws times the expected value of the random variable. 

The standard error of the sum of independent draws of a random variable is the square root of the number of draws times the standard deviation of the urn. 

###Equations

Expected value of a random variable: 
*ap+b(1−p)*
Expected value of the sum of n draws of a random variable: 
*n×(ap+b(1−p))*
Standard deviation of an urn with two values: 
*∣b–a∣p(1−p)−−−−−−√*
Standard error of the sum of n draws of a random variable:
*n−−√ ×∣b–a∣p(1−p)−−−−−−−√*

##Averages and Proportions

Random variable times a constant
The expected value of a random variable multiplied by a constant is that constant times its original expected value:

E[aX]=aμ
The standard error of a random variable multiplied by a constant is that constant times its original standard error:

SE[aX]=aσ
Average of multiple draws of a random variable
The expected value of the average of multiple draws from an urn is the expected value of the urn (μ).

The standard deviation of the average of multiple draws from an urn is the standard deviation of the urn divided by the square root of the number of draws (σ/n−−√).

The sum of multiple draws of a random variable
The expected value of the sum of n draws of a random variable is n times its original expected value:

E[nX]=nμ
The standard error of the sum of n draws of random variable is n−−√ times its original standard error:

SE[nX]=n−−√σ

The sum of multiple different random variables
The expected value of the sum of different random variables is the sum of the individual expected values for each random variable:

E[X1+X2+⋯+Xn]=μ1+μ2+⋯+μn
The standard error of the sum of different random variables is the square root of the sum of squares of the individual standard errors:

SE[X1+X2+⋯+Xn]=σ21+σ22+⋯+σ2n−−−−−−−−−−−−−−−√
Transformation of random variables
If X is a normally distributed random variable and a and b are non-random constants, then aX+b is also a normally distributed random variable.

##Law of Large Numbers

The law of large numbers states that as n increases, the standard error of the average of a random variable decreases. In other words, when n is large, the average of the draws converges to the average of the urn.
The law of large numbers is also known as the law of averages.
The law of averages only applies when n is very large and events are independent. It is often misused to make predictions about an event being "due" because it has happened less frequently than expected in a small sample size.

##How Large is Large in CLT?

The sample size required for the Central Limit Theorem and Law of Large Numbers to apply differs based on the probability of success.
If the probability of success is high, then relatively few observations are needed.
As the probability of success decreases, more observations are needed.
If the probability of success is extremely low, such as winning a lottery, then the Central Limit Theorem may not apply even with extremely large sample sizes. The normal distribution is not a good approximation in these cases, and other distributions such as the Poisson distribution (not discussed in these courses) may be more appropriate.

##How Large is Large in CLT?

The sample size required for the Central Limit Theorem and Law of Large Numbers to apply differs based on the probability of success.
If the probability of success is high, then relatively few observations are needed.
As the probability of success decreases, more observations are needed.
If the probability of success is extremely low, such as winning a lottery, then the Central Limit Theorem may not apply even with extremely large sample sizes. The normal distribution is not a good approximation in these cases, and other distributions such as the Poisson distribution (not discussed in these courses) may be more appropriate.

##Assesent Part 3

This is a 6-part question asking you to determine some probabilities of what happens when a student guessed for all of their answers on the SAT. Use the information below to inform your answers for the following questions.

An old version of the SAT college entrance exam had a -0.25 point penalty for every incorrect answer and awarded 1 point for a correct answer. The quantitative test consisted of 44 multiple-choice questions each with 5 answer choices. Suppose a student chooses answers by guessing for all questions on the test.

What is the probability of guessing correctly for one question?
```{r}
p <- 1/5
p
```

What is the expected value of points for guessing on one question?
```{r}
a <- 1
b <- -0.25
mu <- a*p + b*(1-p)
mu
```

What is the expected score of guessing on all 44 questions?
```{r}
44*(a*p+b*(1−p))
```

What is the standard error of guessing on all 44 questions?
```{r}
sigma <- abs(b-a)*sqrt(p*(1-p))*sqrt(44)
sigma
```

Use the Central Limit Theorem to determine the probability that a guessing student scores 8 points or higher on the test.
```{r}

```


Expected value of a random variable: 
*ap+b(1−p)*
Expected value of the sum of n draws of a random variable: 
*n×*
Standard deviation of an urn with two values: 
*∣b–a∣p(1−p)−−−−−−√*
Standard error of the sum of n draws of a random variable:
*n−−√ ×∣b–a∣p(1−p)−−−−−−−√*